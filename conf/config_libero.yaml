defaults:
  - callbacks: libero
  - datamodule: libero
  - model: flower 
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

root_data_dir: /home/yagmurlu/code/MoDE_Calvin/dataset/task_ABC_D
lang_folder: lang_clip_resnet50

freeze_florence: False
load_pretrained: True

log_dir: ./logs
slurm: false
seed: 42
device: 'cuda'
batch_size: 80
#batch_size: 8
devices: 1
goal_window_size: 1
act_dim: 7
proprio_dims: 9
obs_dim: 512
goal_dim: 512
obs_seq_len: 1
act_seq_len: 10
multistep: ${act_seq_len}
p_last_state: 0
max_epochs: 100
rollout_lh_skip_epochs: 99
num_workers: 1
benchmark_name: ${libero_benchmark} # calvin_abcd
libero_benchmark: libero_10 # libero_goal # libero_spatial, libero_object, LIBERO_GOAL, LIBERO_90, LIBERO_10

n_heads: 16
n_layers: 18
#n_layers: 30
affine_dim: 256
#n_layers: 30
#dit_dim: 1024
attn_pdrop: 0.1
resid_pdrop: 0.1
mlp_pdrop: 0.1

backbone: "mlp"
#backbone: "mse"
block_depth: 3
action_noise_mult: 0.05
use_plu: true
#
trainer:
  devices: ${devices}
  precision: bf16-mixed
  max_epochs: ${max_epochs}
  sync_batchnorm: True
  accelerator: gpu
  strategy: "ddp"
  limit_train_batches: 1000
  limit_val_batches: 4

logger:
  _target_: pytorch_lightning.loggers.WandbLogger
  save_dir: .
  name: logger
  group: mode
  log_model: false
  project: flower_vla
  entity: tarasovd
  id: ???


hydra:
  run:
    dir: ${log_dir}/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${log_dir}/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.override_dirname}
  job:
    config:
      override_dirname:
        exclude_keys:
          - log_dir
          - datamodule.root_data_dir
          - trainer.gpus
          - datamodule.num_workers
          - trainer.limit_train_batches
          - trainer.limit_val_batches